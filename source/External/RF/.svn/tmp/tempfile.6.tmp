#include "nodegini.h"
#include "nodesvm.h"

NodeGini::NodeGini(HyperParameters hp, int depth) : Node(hp, depth), m_bestFeature( -1 ),
                                            m_bestThreshold( 0.0 )
{

}

NodeGini::NodeGini(HyperParameters hp, int depth, int reset) : Node(hp, depth, reset), m_bestFeature( -1 ),
                                            m_bestThreshold( 0.0 )
{

}

std::pair<float, float> NodeGini::calcGiniAndThreshold(const std::vector<int>& labels,
                                                   const std::vector<std::pair<float, int> >& responses)
{
    // Initialize the counters: left takes all at the begining
    double DGini, LGini, RGini, LTotal, RTotal, bestW0 = 0, bestDGini = 1e10;
    std::vector<double> LCount(m_hp.numClasses, 0.0), RCount(m_hp.numClasses, 0.0);

    RTotal = responses.size();
    LTotal = 0;

    // Count the number of samples in each class
    std::vector<std::pair<float, int> >::const_iterator resIt(responses.begin()), resEnd(responses.end()), tmpResIt;
    for (; resIt != resEnd; resIt++)
    {
        RCount[labels[resIt->second]]++;
    }

    // Loop over the sorted values and find the min DGini
    std::vector<double>::iterator LIt = LCount.begin(), RIt = RCount.begin(), end = LCount.end(), REnd = RCount.end();
    resIt = responses.begin();
    ++resIt;
    for (; resIt != resEnd; resIt++)
    {
        tmpResIt = resIt;
        --tmpResIt;

        RTotal--;
        LTotal++;
        RCount[labels[tmpResIt->second]]--;
        LCount[labels[tmpResIt->second]]++;

        LGini = 0;
        RGini = 0;
        LIt = LCount.begin();
        RIt = RCount.begin();
        for (; LIt != end; LIt++, RIt++)      // Calculate Gini index
        {
            LGini += (*LIt/LTotal)*(1 - *LIt/LTotal);
            RGini += (*RIt/RTotal)*(1 - *RIt/RTotal);
        }

        DGini = (LTotal*LGini + RTotal*RGini)/responses.size();
        if (DGini < bestDGini)
        {
            bestDGini = DGini;
            bestW0 = (resIt->first + tmpResIt->first)*0.5;
        }
    }

    return std::pair<float,float>((float)bestDGini,(float)bestW0);
}

void NodeGini::findHypotheses(const matrix<float>& data, const std::vector<int>& labels,
                          const std::vector<int>& inBagSamples, const std::vector<int>& randFeatures)
{
    std::vector<double> gini(m_hp.numRandomFeatures), thresholds(m_hp.numRandomFeatures);
    std::vector<int>::const_iterator it(randFeatures.begin());
    std::vector<int>::const_iterator end(randFeatures.end());

    std::vector<int>::const_iterator bagIt;
    std::vector<int>::const_iterator bagEnd(inBagSamples.end());

    double bestDGini = 1e10, bestThreshold = 0;
    int bestFeature = *it;
    std::pair<float,float> curGiniThresh;
    std::vector<std::pair<float, int> > responses;

    while ( it != end )
    {
        responses.clear();
        responses.reserve(inBagSamples.size());
        bagIt = inBagSamples.begin();
        while ( bagIt != bagEnd )
        {
            responses.push_back(std::pair<float, int>(data(*bagIt,*it),*bagIt));
            ++bagIt;
        }
        sort(responses.begin(), responses.end());

        curGiniThresh = calcGiniAndThreshold(labels, responses);
        if (curGiniThresh.first < bestDGini)
        {
            bestDGini = curGiniThresh.first;
            bestFeature = *it;
            bestThreshold = curGiniThresh.second;
        }

        ++it;
    }

    m_bestFeature = bestFeature;
    m_bestThreshold = (float) bestThreshold;
}

void NodeGini::evalNode(const matrix<float>& data, const std::vector<int>& inBagSamples,
                    std::vector<int>& leftNodeSamples, std::vector<int>& rightNodeSamples)
{
    std::vector<int>::const_iterator it(inBagSamples.begin());
    std::vector<int>::const_iterator end(inBagSamples.end());
    while ( it != end )
    {
        if (data(*it,m_bestFeature) > m_bestThreshold)
        {
            rightNodeSamples.push_back(*it);
        }
        else
        {
            leftNodeSamples.push_back(*it);
        }
        ++it;
    }
}


NODE_TRAIN_STATUS NodeGini::train(const matrix<float>& data, const std::vector<int>& labels, std::vector<int>& inBagSamples,
                 matrix<float>& confidences, std::vector<int>& predictions)
{
    bool doSplit = shouldISplit(labels,inBagSamples);

    NODE_TRAIN_STATUS myTrainingStatus = IS_NOT_LEAF;

    if ( doSplit )
    {
        m_isLeaf = false;

        //train here the node: Select random features and evaluate them
        std::vector<int> randFeatures = randPerm(data.size2(), m_hp.numRandomFeatures);

        findHypotheses(data, labels, inBagSamples, randFeatures);
        if (m_hp.verbose) {
            cout << "Node #: " << m_nodeIndex << " selected feature #: " << m_bestFeature;
            cout << " and the threshold is: " << m_bestThreshold << " at depth " << m_depth << endl;
        }

        // split the data
        std::vector<int> leftNodeSamples, rightNodeSamples;
        evalNode(data,inBagSamples,leftNodeSamples,rightNodeSamples);

        // pass them to the left and right child, respectively
        m_leftChildNode = Ptr(new NodeGini(m_hp,m_depth + 1));
        m_rightChildNode = Ptr(new NodeGini(m_hp,m_depth + 1));

        NODE_TRAIN_STATUS leftChildStatus = m_leftChildNode->train(data,labels,leftNodeSamples,confidences,predictions);
        NODE_TRAIN_STATUS rightChildStatus= m_rightChildNode->train(data,labels,rightNodeSamples,confidences,predictions);

        if (leftChildStatus == IS_LEAF && rightChildStatus == IS_LEAF) {
            myTrainingStatus = CHANGE_TO_SVM;
        }
        else if (leftChildStatus == CHANGE_TO_SVM) {
            m_leftChildNode.reset(new NodeSVM( m_hp, m_depth + 1));
            leftChildStatus = m_leftChildNode->train(data,labels,leftNodeSamples,confidences,predictions);
        }
        else if (rightChildStatus == CHANGE_TO_SVM) {
            m_rightChildNode.reset(new NodeSVM( m_hp, m_depth + 1));
            rightChildStatus = m_rightChildNode->train(data,labels,rightNodeSamples,confidences,predictions);
        }
    }
    else
    {
        if (m_hp.verbose) {
            cout << "Node #: " << m_nodeIndex << " is terminal, at depth " << m_depth << endl;
        }

        // calc confidence, labels, etc
        m_isLeaf = true;
        myTrainingStatus = IS_LEAF;
        m_nodeConf.resize(m_hp.numClasses);
        std::vector<float>::const_iterator confIt(m_nodeConf.begin());
        std::vector<float>::iterator It = m_nodeConf.begin(), end = m_nodeConf.end();
        for (; It != end; It++)
        {
            *It = 0;
        }

        std::vector<int>::const_iterator sampIt(inBagSamples.begin()), sampEnd(inBagSamples.end());
        for (; sampIt != sampEnd; sampIt++)
        {
            m_nodeConf[labels[*sampIt]]++;
        }

        int bestClass = 0, tmpN = 0;
        float bestConf = 0;
        It = m_nodeConf.begin();
        for (; It != end; It++, confIt++)
        {
            *It /= inBagSamples.size();

            if (*It > bestConf)
            {
                bestConf = *It;
                bestClass = tmpN;
            }
            tmpN++;
        }

        m_nodeLabel = bestClass;

        sampIt = inBagSamples.begin();
        for (; sampIt != sampEnd; sampIt++)
        {
            predictions[*sampIt] = m_nodeLabel;
            It = m_nodeConf.begin();
            for (int n = 0; It != end; It++, n++)
            {
                confidences(*sampIt, n) = *It;
            }
        }
    }

    return myTrainingStatus;
}

void NodeGini::eval(const matrix<float>& data, const std::vector<int>& labels, const std::vector<int>& sampleIndeces,
                matrix<float>& confidences, std::vector<int>& predictions)
{
    if (m_isLeaf) {
        // Make predictions and confidences
        std::vector<int>::const_iterator sampIt(sampleIndeces.begin()), sampEnd(sampleIndeces.end());
        std::vector<float>::const_iterator It, end(m_nodeConf.end());

        for (; sampIt != sampEnd; sampIt++)
        {
            predictions[*sampIt] = m_nodeLabel;
            It = m_nodeConf.begin();
            for (int n = 0; It != end; It++, n++)
            {
                confidences(*sampIt, n) = *It;
            }
        }
    }
    else {
        // split the data

        std::vector<int> leftNodeSamples, rightNodeSamples;
        evalNode(data,sampleIndeces,leftNodeSamples,rightNodeSamples);

        m_leftChildNode->eval(data,labels,leftNodeSamples,confidences,predictions);
        m_rightChildNode->eval(data,labels,rightNodeSamples,confidences,predictions);
    }
}




